# 第3章 入门的antlr项目

>识别 `{1, 2, 3}` 和 `{1, {2, 3}, 4}` 这样的初始化语句。

## 3.1 antlr工具、运行库以及自动生成的代码

```antlrv4
/**
 * 语法文件以 grammar 关键字开头；
 * 这是一个名为 ArrayInit 的语法，必须和文件名ArrayInit.g4匹配。
 */
grammar ArrayInit;

// 一条名为init的rule
init : '{' value (',' value)* '}' ;

// 一个value可以是一个嵌套的init，也可以是一个简单的整数
value: init
        | INT
        ;

// 语法分析器的rule必须以小写字母开头，词法分析器的规则则必须用大写字母开头
// 定义 token INT，由一个或者多个数字组成
INT: [0-9]+;
// 定义lexer rule，丢弃空白符号
WS : [ \t\r\n]+ -> skip;
```

>编译

```bash
antlr4 ArrayInit.g4 -package com.xxx.ch03
javac -classpath /usr/local/lib/antlr-4.6-complete.jar *.java
```

```
-rw-r--r--  1 0x822a5b87  staff   583B Jun 12 09:23 ArrayInit.g4
-rw-r--r--  1 0x822a5b87  staff    50B Jun 12 09:23 ArrayInit.tokens
-rw-r--r--  1 0x822a5b87  staff   1.0K Jun 12 09:23 ArrayInitBaseListener.class
-rw-r--r--  1 0x822a5b87  staff   1.6K Jun 12 09:23 ArrayInitBaseListener.java
-rw-r--r--  1 0x822a5b87  staff   3.4K Jun 12 09:23 ArrayInitLexer.class
-rw-r--r--  1 0x822a5b87  staff   3.2K Jun 12 09:23 ArrayInitLexer.java
-rw-r--r--  1 0x822a5b87  staff    50B Jun 12 09:23 ArrayInitLexer.tokens
-rw-r--r--  1 0x822a5b87  staff   473B Jun 12 09:23 ArrayInitListener.class
-rw-r--r--  1 0x822a5b87  staff   894B Jun 12 09:23 ArrayInitListener.java
-rw-r--r--  1 0x822a5b87  staff   1.2K Jun 12 09:23 ArrayInitParser$InitContext.class
-rw-r--r--  1 0x822a5b87  staff   1.1K Jun 12 09:23 ArrayInitParser$ValueContext.class
-rw-r--r--  1 0x822a5b87  staff   5.2K Jun 12 09:23 ArrayInitParser.class
-rw-r--r--  1 0x822a5b87  staff   5.7K Jun 12 09:23 ArrayInitParser.java
```

>简单介绍一下生成的文件
> 
- `ArrayInitParser.java` parser
- `ArrayInitLexer.java` lexer，由antlr通过分析词法规则INT和WS，以及字面值 '{', ',', '}' 生成。
- `ArrayInit.tokens` antlr 会给我们定义的词法符号指定一个**数字形式的类型**，然后存储到该文件
- `ArrayInitListener.java` 和 `ArrayInitBaseListener.java` 遍历语法树时通过该鉴定器回调代码

### antlr语法比正则表达式功能更强大

> 正则表达式没有存储的概念，他们无法记住之前匹配过的输入。因此，他们不能将左右花括号正确配对。
> 我们将在后续的**嵌套模式**讨论这个问题。

## 3.2 测试生成的语法分析器

```bash
javac *.java
# ArrayInit -> GrammarName
# init      -> startRuleName
grun ArrayInit init -tokens
# {99, 3, 451}
```

> 输出为，其中 `[@5,8:10='451',<INT>,1:8]`
> 代表是第五个 token，在文本中以第8个字符开始，第10个字符结束，类型是INT，位于文本的第1行的第8个字符。

```
{99, 3, 451}
[@0,0:0='{',<'{'>,1:0]
[@1,1:2='99',<INT>,1:1]
[@2,3:3=',',<','>,1:3]
[@3,5:5='3',<INT>,1:5]
[@4,6:6=',',<','>,1:6]
[@5,8:10='451',<INT>,1:8]
[@6,11:11='}',<'}'>,1:11]
[@7,13:12='<EOF>',<EOF>,2:0]
```

> 也可以输出语法树

```
grun ArrayInit init -tree
```

> 结果以lisp的风格输出语法树

```
(init { (value 99) , (value 3) , (value 451) })
```

> 也可以通过 `-gui` 打开一个 UI

## 3.3 将生成的语法分析器与java程序集成

```java
public class ArrayInit {

    public static void main(String[] args) throws IOException {
        // 输入
        CharStream input = CharStreams.fromStream(System.in);
        // lexer
        ArrayInitLexer lexer = new ArrayInitLexer(input);
        // 使用lexer将输入转换为tokens
        CommonTokenStream tokens = new CommonTokenStream(lexer);
        // 使用parser解析tokens内容
        ArrayInitParser parser = new ArrayInitParser(tokens);

        // 针对init规则开始进行语法分析，注意，这里的init指的只是init rule，而不是常规的init方法
        InitContext tree = parser.init();
        System.out.println(tree.toStringTree(parser));
    }
}
```

## 3.4 构建一个语言类应用程序

>首先新建一个监听器

```java
public class Short2UnicodeString extends ArrayInitBaseListener {

    @Override
    public void enterInit(InitContext ctx) {
        System.out.print('"');
    }

    @Override
    public void exitInit(InitContext ctx) {
        System.out.print('"');
    }

    @Override
    public void enterValue(ValueContext ctx) {
        // 假定不存在嵌套结构
        // enterValue 函数的参数是 ValueContext，我们通过它可以获取INT token的文本值
        int value = Integer.parseInt(ctx.INT().getText());
        System.out.printf("\\u%04x", value);
    }
}
```
> 然后在rule解析完毕之后，通过迭代器对ast进行遍历，在遍历的过程中，会自动触发我们的监听器的回调函数。

```java
public class Translate {

    public static void main(String[] args) throws IOException {
        // 输入
        CharStream input = CharStreams.fromString(args[0]);
        // lexer
        ArrayInitLexer lexer = new ArrayInitLexer(input);
        // 使用lexer将输入转换为tokens
        CommonTokenStream tokens = new CommonTokenStream(lexer);
        // 使用parser解析tokens内容
        ArrayInitParser parser = new ArrayInitParser(tokens);

        // 解析rule init，前面提到的过的，rule 的根节点是其对应的 RuleContext
        InitContext tree = parser.init();
        ParseTreeWalker walker = new ParseTreeWalker();
        walker.walk(new Short2UnicodeString(), tree);
        System.out.println();
    }
}
```


































